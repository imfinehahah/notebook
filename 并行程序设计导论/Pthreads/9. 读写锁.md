现在，来让我们看看对一个大的、共享的、能够被线程简单搜索和更新的数据结构的访问控制。这里假设该数据结构为链表，能够支持查询、插入和删除操作



定义链表结构：

```c++
struct node {
	int value;
    struct node* next;
}
```

查询操作：

```c++
int Member(int value, struct node* head) {
    struct node* cur = head;

    while (cur != NULL && cur->value < value) {
        cur = cur->next;
    }

    if (cur == NULL || cur->value > value) {
        return 0; 
    } else {
        return 1;
    }
}
```

插入操作：

```c++
int Insert(int value, struct node** head) {
    struct node* cur = *head;
    struct node* pre = NULL;
    struct node* temp;

    while (cur != NULL && cur->value < value) {
        pre = cur;
        cur = cur->next;
    }

    if (cur == NULL || cur->value > value) {
        temp = (struct node*)malloc(sizeof(struct node));
        temp->value = value;
        temp->next = cur;
        if (pre != NULL) {
            pre->next = temp;
        } else {
            *head = temp;
        }
        return 1;
    } else {
        return 0;
    }
}
```

删除操作：

```c++
int Delete(int value, struct node** head) {
    struct node* cur = *head;
    struct node* pre = NULL;
    struct node* temp;

    while (cur != NULL && cur->value < value) {
        pre = cur;
        cur = cur->next;
    }

    if (cur != NULL && cur->value == value) {
        if (pre == NULL) {
            *head = cur->next;
            free(temp);
        } else {
            pre->next = cur->next;
            free(cur);
        }
        return 1;
    } else {
        return 0;
    }
}
```



**多线程链表**

​	多个线程可以没有冲突地同时读取一个内存单元，因此多个线程可以同时执行 member 函数，但 insert 和 delete 需要写内存，如果试图让这类操作与其他操作同时执行，那么可能会有问题。

* 问题1：如果线程0执行查询5的操作，线程1执行删除5的操作，那么线程0可能报道5在链表中，然而5可能已经在线程0返回前被删除了
* 问题2：如果线程0正在执行查询8的操作，线程1可能会在线程0查找到8之前释放掉5的节点。尽管典型的 free 实现不覆盖释放的内存，但如果内存在线程0到达之前进行了重新分配，那么将会产生严重的问题。比如，如果内存被重新分配用于其他用途，而不是作为链表的节点，那么线程0会“认为” next 成员以及设置为垃圾，并且在执行 `cur = cur->next` 后，对 cur 的引用可能会导致段违规



通常，可以把问题归结为：在执行 insert 或 delete 的同时执行其他操作。多线程同时执行 member 操作，即读链表节点是没有问题的；但多个线程同时访问链表且至少有一个线程正在执行 insert 或 delete 操作，即写链表节点时，是不安全的。



**第一种解决方法**

我们使用单一的互斥量来解决，即每次执行这三个操作时，用一个互斥量来处理，某种意义上就和串行是一样的：

```c++
pthread_mutex_lock(&mutex);
/* do*/
pthread_mutex_unlock(&mutex);
```

这种解决方法的问题是，如果对链表的大部分的访问操作是 member，那么失去了开发并行性的机会。另一方面，如果对链表的大部分访问操作是 insert 和 delete ，这可能是最好的解决方案，因为大部分的操作都需要串行执行，而这个解决方案很容易实现



**第二种解决方法**

使用 “细粒度” 的锁，即对链表中的单个节点上锁，而不是对整个链表上锁，例如，我们可以在链表节点的结构中添加一个互斥量：

```c++
struct node {
	int value;
    struct node* next;
    pthread_mutex_t mutex;
}
```

现在，每次访问一个节点时，必须先对该节点加锁，注意，这要求有一个与 head_p 指针相关联的互斥量。因此，我们可以重新实现 member 函数，这个函数比原来的实现更复杂，也比原来的实现慢，因为每次访问一个节点时，我们都必须对节点加锁和解锁，所以每一次的结点访问至少增加两次函数调用；另外，如果线程需要等待锁，又会增加附加的延迟。而且每个节点增加了互斥量，也会增加整个链表对存储量的需求

但从另一方面看，细粒度的锁可能真的是一个更接近需求的方案。因为只对当前感兴趣的节点加锁，所以多个线程能同时访问链表的不同部分，不管它们在执行什么操作



用每个链表结点拥有一个互斥量的方法来实现 Member 函数：

```c++
int Member(int value) {
    struct node* temp;

    pthread_mutex_lock(&head_mutex);
    temp = head;

    while (temp != NULL && temp->value < value) {
        if (temp->next != NULL) {
            pthread_mutex_lock(&temp->next->mutex);
        }
        if (temp == head) {
            pthread_mutex_unlock(&head_mutex);
        }
        pthread_mutex_unlock(&temp->mutex);
        temp = temp->next;
    }

    if (temp == NULL || temp->value > value) {
        if (temp == head) {
            pthread_mutex_unlock(&head_mutex);
        }
        if (temp != NULL) {
            pthread_mutex_unlock(&(temp->mutex));
        }
        return 0;
    } else {
        if (temp == head) {
            pthread_mutex_unlock(&head_mutex);
        }
        pthread_mutex_unlock(&(temp->mutex));
        return 1;
    }
}
```

插入操作和删除操作可以看看怎么实现



**Pthreads 读写锁**

前面我们介绍了两种多线程链表的方法，这两种方法都不让执行 member 函数的线程还可以同时访问链表的任意节点。第一种方法在任一时刻只允许一个线程访问整个链表，第二个方法在任意时刻只允许一个线程访问任一给定节点。

下面来介绍读写锁。读写锁可以作为另一种可选方案，除了提供两个锁函数以外，其与互斥量差不多。这两个函数一个为读操作加锁，另一个为写操作加锁。多个线程能通过调用读锁函数而同时获得锁，但只有一个线程能通过写函数获得锁。

**因此，如果任何线程拥有了读锁，则任何请求写锁的线程讲阻塞在写锁函数的调用上。而且，如果任何线程拥有了写锁，则任何想获取读或写锁的线程讲阻塞在它们对应的锁函数上。**

eg：

```c++
pthread_rwlock_rdlock(&rwlock);
Member(v);
pthread_rwlock_unlock(&rwlock);

pthread_rwlock_wrlock(&rwlock);
Insert(v);
pthread_rwlock_unlock(&rwlock);

pthread_rwlock_wrlock(&rwlock);
Delete(v);
pthread_rwlock_unlock(&rwlock);
```



读写锁的语法

初始化一个读写锁：

```c++
int pthread_rwlock_init(pthread_rwlock_t* rwlock_p,
                       const pthread_rwlockattr_t* attr_p);
```

我们一般不使用第二个参数，一般赋值为 NULL

释放一个读写锁：

```c++
int pthread_mutex_destory(pthread_rwlock_t* rwlock_p);
```

锁函数：

```c++
int pthread_rwlock_rdlock(pthread_rwlock_t* rwlock_p); // 读加锁
int pthread_rwlock_wrlock(pthread_rwlock_t* rwlock_p); // 写加锁
int pthread_rwlock_unlock(pthread_rwlock_t* rwlock_p); // 解锁
```



**不同方案实现的性能**

下面来看看哪种方案实现的性能最好，在程序中，主线程首先向空链表中插入用户指定数量的随机生成的键值。被主线程启动后，每个线程对链表执行用户指定数量的操作。用户还有指定每类操作所占的百分比。然而，哪个操作发生以及对哪个键值进行操作取决于一个随机数生成器。

下表是关于一个初始包含1000个键值，执行100000个操作所花的时间，其中第一个的键值是1000个，操作是100000次，然后member的执行占比 99.9%，其他占比 0.1%，然后另外一个键值也是1000个，操作是100000次，80%是member，插入是10%，删除是10%。

![1678062041738](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\1678062041738.png)

我们注意到，当线程数为1时，读写锁与单互斥量实现的执行时间是一样的，因为没有读写锁和互斥量的竞争，这些操作是串行执行的，每个节点一个锁的实现比较慢。

在多个线程的情况下，每个节点一个互斥量的实现仍然维持其低效性。与其他两个实现相比，过多的加锁和解释使这个实现开销太大。

在多线程情况下，且 insert 和 delete 操作非常少时，读写锁远好于单互斥量实现，因为访问节点的操作可以并发访问，而互斥量只能串行操作。另外，当 insert 和 delete 操作较多时，读写锁和单互斥量的实现的性能几乎没有差别。因此对链表来说，读写锁能够提供很大的性能提示，但得 insert 和 delete 操作非常少才行

对于读写锁实现，当有大量写锁操作时，会出现太多的锁竞争，综合性能下降得很快。读写锁实现比单互斥量和每个节点一个互斥量的操作的实现更好。除非 insert 和 delete 占的比例很小，否则串行执行是更好的方案。



**实现读写锁**

典型的读写锁实现定义了一个数据结构，该结构使用两个条件变量，一个表示读者，另一个表示写者，还有一个互斥量。这个数据结构还包括一些成员

* 多少读者拥有锁，即有多少线程同时在读
* 多少读者正在等待获取锁
* 是否有一个写者拥有锁
* 多少写者正在等待获取锁

互斥量用于保护读写锁的数据结构：无论何时一个线程调用其中的任意一个函数（读锁、写锁、解锁），它必须首先锁互斥量，并且无论何时一个线程完成了这些函数调用中的一个，它必须解锁互斥量。在获取互斥量后，线程检查合适的数据成员来决定接下来干什么。

比如，如果它想要进行读访问，就检查是否有一个写者当前拥有锁。如果没有，它对活动读者的数量加1，然后继续执行随后的操作。如果有一个活动写者（有一个写者拥有锁，正在写），那么就为等待获取锁的读者的数量加1，并且在读者条件变量上启动一个条件等待。当它被唤醒后，它将正在等待的读者的数量减1，对活动读者的数量加1，并继续执行随后的操作。写锁函数的实现与读锁函数相类似

解锁函数的操作取决于线程是一个读者还是一个写者。如果线程是一个读者，且没有其他的活动读者，并且一个写者正在等待，那么它就在返回前发送信号通知写者，是写者继续后继的操作。另一方面，如果线程是写者，则可能同时有读者和写者正在等待，因此线程需要决定它倾向于读者还是写者。因为写者必须互斥访问，有可能写者更难获得锁。因此许多实现给予写者优先权